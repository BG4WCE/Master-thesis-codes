{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras import callbacks\n",
    "from keras.initializers import VarianceScaling\n",
    "from sklearn.cluster import KMeans\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dataset(X, Y, **options):\n",
    "    \n",
    "    look_back = options.pop('look_back', None)\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(X) - look_back):\n",
    "        a = X[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(Y[i + look_back - 1])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "look_back = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = glob.glob(r'C:\\Keras_Deep_Clustering\\csv_trafficnet_splitted_3\\*.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Keras_Deep_Clustering\\csv_trafficnet_splitted_3\\11.csv\n",
      "(50000, 4) (50000,)\n",
      "(49950, 50, 4) (49950,)\n",
      "C:\\Keras_Deep_Clustering\\csv_trafficnet_splitted_3\\12.csv\n",
      "(50000, 4) (50000,)\n",
      "(49950, 50, 4) (49950,)\n",
      "C:\\Keras_Deep_Clustering\\csv_trafficnet_splitted_3\\13.csv\n",
      "(50000, 4) (50000,)\n",
      "(49950, 50, 4) (49950,)\n",
      "C:\\Keras_Deep_Clustering\\csv_trafficnet_splitted_3\\14.csv\n",
      "(50000, 4) (50000,)\n",
      "(49950, 50, 4) (49950,)\n",
      "C:\\Keras_Deep_Clustering\\csv_trafficnet_splitted_3\\15.csv\n",
      "(50000, 4) (50000,)\n",
      "(49950, 50, 4) (49950,)\n",
      "C:\\Keras_Deep_Clustering\\csv_trafficnet_splitted_3\\16.csv\n",
      "(50000, 4) (50000,)\n",
      "(49950, 50, 4) (49950,)\n",
      "C:\\Keras_Deep_Clustering\\csv_trafficnet_splitted_3\\17.csv\n",
      "(50000, 4) (50000,)\n",
      "(49950, 50, 4) (49950,)\n",
      "C:\\Keras_Deep_Clustering\\csv_trafficnet_splitted_3\\18.csv\n",
      "(50000, 4) (50000,)\n",
      "(49950, 50, 4) (49950,)\n",
      "C:\\Keras_Deep_Clustering\\csv_trafficnet_splitted_3\\19.csv\n",
      "(50000, 4) (50000,)\n",
      "(49950, 50, 4) (49950,)\n",
      "C:\\Keras_Deep_Clustering\\csv_trafficnet_splitted_3\\20.csv\n",
      "(50000, 4) (50000,)\n",
      "(49950, 50, 4) (49950,)\n",
      "C:\\Keras_Deep_Clustering\\csv_trafficnet_splitted_3\\21.csv\n",
      "(50000, 4) (50000,)\n",
      "(49950, 50, 4) (49950,)\n",
      "C:\\Keras_Deep_Clustering\\csv_trafficnet_splitted_3\\22.csv\n",
      "(50000, 4) (50000,)\n",
      "(49950, 50, 4) (49950,)\n",
      "C:\\Keras_Deep_Clustering\\csv_trafficnet_splitted_3\\23.csv\n",
      "(50000, 4) (50000,)\n",
      "(49950, 50, 4) (49950,)\n",
      "C:\\Keras_Deep_Clustering\\csv_trafficnet_splitted_3\\24.csv\n",
      "(50000, 4) (50000,)\n",
      "(49950, 50, 4) (49950,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_all = np.empty((1, 20, 21))\n",
    "Y_all = np.empty((1,))\n",
    "\n",
    "for i in range(0,14):\n",
    "    print(path[i])\n",
    "    \n",
    "    CutIn = pd.read_csv(path[i], usecols=[ 'LatitudeWsu','LongitudeWsu','GpsHeadingWsu','GpsSpeedWsu',\n",
    "                                          'SpeedWsu','LaneDistanceLeft','LaneDistanceRight','LaneHeading',\n",
    "                                          'CutIn','o1','o2','o3','r1','r2','r3','t1','t2','t3','tt2','tt3',\n",
    "                                          'c2','c3'])\n",
    "    \n",
    "    \n",
    "    CutIn.fillna(-1, inplace=True)\n",
    "\n",
    "    \n",
    "        \n",
    "    Y_train = np.array(CutIn['CutIn'].values)\n",
    "    X_train = np.array(CutIn[[ 'LatitudeWsu','LongitudeWsu','GpsHeadingWsu','GpsSpeedWsu','SpeedWsu',\n",
    "                              'LaneDistanceLeft','LaneDistanceRight','LaneHeading','o1','o2','o3','r1',\n",
    "                              'r2','r3','t1','t2','t3','tt2','tt3','c2','c3' ]])\n",
    "\n",
    "    dimof_output = 1\n",
    "    dimof_input = X_train.shape[1]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    print(X_train.shape, Y_train.shape)\n",
    "    \n",
    "    X, Y = create_dataset(X_train, Y_train, look_back=look_back)\n",
    "    print(X.shape, Y.shape)\n",
    "    \n",
    "    X_all = np.append(X_all, X, axis=0)\n",
    "    Y_all = np.append(Y_all, Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699301"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_all[0]=0\n",
    "len(Y_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(np.isnan(Y_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.37081167e-311,  1.37081167e-311,  1.37081167e-311, ...,\n",
       "         1.37126614e-311,  1.37126614e-311,  1.37126614e-311],\n",
       "       [-3.42241092e-001, -1.00652633e+000,  5.68545268e-001, ...,\n",
       "        -9.83169451e-001,  7.02579054e-001, -3.01201441e-002],\n",
       "       [-3.42241092e-001, -1.00652633e+000,  5.75580525e-001, ...,\n",
       "        -9.83169451e-001,  7.03306839e-001,  8.59067625e-002],\n",
       "       ...,\n",
       "       [-2.01697043e+000, -1.08340270e+000, -1.33790628e+000, ...,\n",
       "        -1.08340270e+000, -7.98828761e-001,  2.31583303e+000],\n",
       "       [-2.01697043e+000, -1.08340270e+000, -1.34111132e+000, ...,\n",
       "        -1.08340270e+000, -7.87480715e-001,  2.13049331e+000],\n",
       "       [-2.01697043e+000, -1.08340270e+000, -1.34111132e+000, ...,\n",
       "        -1.08340270e+000, -7.85090161e-001,  2.13049331e+000]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all = X_all.reshape((X_all.shape[0], -1))\n",
    "x_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139860200"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all = x_all.astype(np.uint8)\n",
    "x_all.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "standardized_X = preprocessing.scale(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all = np.round(standardized_X , 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699301"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "868.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "kmeans_under = KMeans(n_clusters=2, n_init=20 , n_jobs=4)   \n",
    "y_pred_kmeans = kmeans_under.fit_predict(x_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699301,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_kmeans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113503"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "868.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n",
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8364495403266976"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.acc(Y_all, y_pred_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[584930, 113503],\n",
       "       [   868,      0]], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(Y_all.round() , y_pred_kmeans )\n",
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAEGCAYAAABIGw//AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAb80lEQVR4nO3dfbRcVZnn8e/v3iQQmpcAAYwJEoSgxrSEECBLFigiITjdBrrRAXqZSLNkmsEZhGlb4rSDrbIaVveIooIGiQS6IaAMTUZDhwyQgXbxFkI6IaArIbyFZIgxkXeEwDN/nH2huJ6qe25S59apqt/Hddat89Sus/dNyZOdffbZWxGBmZlVT0+rG2BmZvmcoM3MKsoJ2sysopygzcwqygnazKyinKDNzCrKCbqiJL1H0gJJj0t6VNIiSYdIGi/pkZLq3EnSjZLWSrpf0vgy6ulELfq+jpW0XNI2SaeWUYe1lhN0BUkScAuwNCIOioiJwFeB/Uqu+ixga0QcDFwGXFpyfR2hhd/X08DngetLrsdaxAm6mo4D3oiIH/YFImJFRNxTWyj1zu5Jvajlkj6a4mMk3S1phaRHJB0jqVfSNel8laTzc+qdCcxPr38GHJ+SjzXWku8rIp6MiJXAW2X/gtYaw1rdAMs1CXioQLlNwAkR8ZqkCcANwFTgDGBxRFwsqRfYBZgMjI2ISQCSRuVcbyzwDEBEbJP0PLA3sHlHf6EO16rvyzqcE3R7Gw58X9Jk4E3gkBR/EJgnaTjwLxGxQtI64P2Svgf8Arg953p5vWWvBdA8zf6+rMN5iKOaVgOHFyh3PvAccChZT2wEQETcDRwLPAtcJ2lWRGxN5ZYC5wI/zrneemB/AEnDgD2ALTvyi3SJVn1f1uGcoKvpTmAnSV/oC0g6QtLH+pXbA9gYEW8BnwN6U9kDgE0RcRVwNTBF0migJyJuBr4GTMmpdyEwO70+FbgzvJpWEa36vqzDyf/9VZOk9wLfIeuZvQY8CXwJeAP4eURMSuOYNwOvAHcB/yUidpU0G/hyKvsSMAvYHfgJ7/ylPCcibutX587AdcBhZD3n0yJiXZm/Z6do0fd1BNnskT1Tnf8vIj5c5u9pQ8sJ2sysojzEYWZWUU7QZmYV5QRtZlZRTtBmZhXlBN2hJJ3d6jbY4Pg7s/6coDuX/2NvP/7O7F2coM3MKqrr50Fr2MjQiN1a3Yymi22vomEjW92MUnzo4HGtbkIptm7ZzJ57jW51M0rx6KqHN0fEPtv7+d7dD4jY9mqhsvHqbxZHxIztratKun6xJI3YjZ0+8NlWN8MG4YaFf9/qJtggHfq+3Z/akc/HtlcL/3f62oofdMzfcl2foM2sHQjUfSOyTtBmVn0Cenpb3Yoh5wRtZu2hCzf3cYI2szbgIQ4zs+pyD9rMrIKEe9BmZtUk96DNzCrLszjMzKrINwnNzKpJeIjDzKyy3IM2M6siD3GYmVWTgF7fJDQzqyaPQZuZVZGHOMzMqss9aDOzinIP2sysguRHvc3MqsuPepuZVZFvEpqZVZeHOMzMKsjrQZuZVZWHOMzMqss3Cc3MKspj0GZmFSQPcZiZVVcX9qC7768kM2tLkgodBa/1pKRVklZIWpZie0laImlN+rlnikvS5ZLWSlopaUrNdWan8mskza6JH56uvzZ9Vo3qqMcJ2swqL9vxqnkJOjkuIiZHxNR0fiFwR0RMAO5I5wAnARPScTZwJVl79gIuAo4CjgQuqkm4V6ayfZ+bMUAduZygzaz6JNRT7NgBM4H56fV84OSa+LWRuQ8YJWkMcCKwJCK2RMRWYAkwI723e0TcGxEBXNvvWnl15HKCNrO2MIge9GhJy2qOs3MuF8Dtkh6qeX+/iNgIkH7um+JjgWdqPrs+xRrF1+fEG9WRyzcJzawtDGL4YnPNsEU9R0fEBkn7Aksk/apR1Tmx2I74oLkHbWZtoZlj0BGxIf3cBNxCNob8XBqeIP3clIqvB/av+fg4YMMA8XE5cRrUkcsJ2syqT4M4BrqU9EeSdut7DUwHHgEWAn0zMWYDt6bXC4FZaTbHNOD5NDyxGJguac90c3A6sDi996KkaWn2xqx+18qrI5eHOMys8sSgZ2g0sh9wS7reMOD6iPhXSQ8CN0k6C3ga+Ewqvwj4FLAWeAU4EyAitkj6JvBgKveNiNiSXp8DXAOMBG5LB8AlderI5QRtZm2hp6c5/+CPiHXAoTnx3wLH58QDOLfOteYB83Liy4BJReuoxwnazNpCE3vQbcMJ2syqr+D4cqdxgjaztuAetJlZBTX5JmHbcII2s7awg49xtyUnaDOrPnmIw8ysspygzcwqygnazKyCfJPQzKzKui8/O0GbWRtQ8x71bidO0GbWFjzEYWZWVd2Xn52gzaw9dGMPurRBHUnvkbRA0uOSHpW0SNIhksZLeqSkOneSdGPa6vx+SePLqMfMhlbR3VQ6LYmXkqDTLgK3AEsj4qCImAh8lWyh7DKdBWyNiIOBy4BLS67PzIaIE3TzHAe8ERE/7AtExIqIuKe2UOpN3yNpeTo+muJjJN0taYWkRyQdI6lX0jXpfJWk83Pqrd3S/GfA8eq0b8ysS6lHhY5OUtYY9CTgoQLlNgEnRMRrkiYANwBTgTPI9va6WFIvsAswGRgbEZMAJI3Kud7b26BHxDZJzwN7A5trC6Vt1rOt1ofvOvjfzsyGXDf2tVp9k3A48H1Jk4E3gUNS/EFgnqThwL9ExApJ64D3S/oe8Avg9pzrFdruPCLmAnMBenbZd7u2QzezIdSliyWVNcSxGji8QLnzgefI9gebCowAiIi7gWOBZ4HrJM2KiK2p3FKy/cF+nHO9t7dBlzQM2APYklPOzNqIAKnY0UnKStB3AjtJ+kJfQNIRkj7Wr9wewMaIeAv4HNCbyh4AbIqIq4CrgSmSRgM9EXEz8DVgSk69tVuanwrcmTZ8NLO21p2zOEoZ4oiIkHQK8B1JFwKvAU8CX+pX9ArgZkmfAe4CXk7xjwNflvQG8BIwi2x8+SeS+v5SmZNT9dVkPe61ZD3n05r2S5lZS/V02A3AIkobg46IDcBn67w9KZVZA3ykJj4nxefzzmyMWnm95to6XwM+M+jGmlm1deDwRRGtvkloZjYg4R60mVlluQdtZlZRnXYDsAgnaDOrPo9Bm5lVk1BXLtjffb+xmbWlZj+oktb3eVjSz9P5gWkVzDVpVcwRKV53lUxJc1L815JOrInPSLG1aaoxjeqoxwnazNpCCQ+qnAc8VnN+KXBZREwAtpKtjgl1VsmUNJHsWYsPAzOAK1LS7wV+AJwETAROT2Ub1ZHLCdrMqq9g77lofpY0DvgPpCUj0qqXnyBbBROy5zBOTq/rrZI5E1gQEb+PiCeAtcCR6VgbEesi4nVgATBzgDpyOUGbWeVla3EU7kGPlrSs5jg755LfAf4GeCud7w38LiK2pfP1ZE8vQ79VMoG+VTLfjvf7TL14ozpy+SahmbWFQYxebI6IqfWvoz8hW+vnIUkf7wvnFI0B3qsXz+v4NipflxO0mbWFJj5JeDTwaUmfAnYGdifrUY+SNCz1cMcBG1L5vlUy1/dbJfPt1TOT2s/kxTc3qCOXhzjMrPrUvJuEETEnIsZFxHiym3x3RsRfkC3YdmoqNhu4Nb2ut0rmQuC0NMvjQGAC8ADZevYT0oyNEamOhekz9erI5QRtZpU3ROtBfwW4IK2GuTfZ6pikn3un+AXAhQARsRq4CXgU+Ffg3Ih4M/WOvwgsJpslclMq26iOXB7iMLM2UM5azxGxlGwTECJiHdkMjP5l6q6SGREXAxfnxBcBi3LiuXXU4wRtZm3Bj3qbmVWRvNyomVkl9c2D7jZO0GbWFpygzcwqqgvzsxO0mbUH96DNzKrIC/abmVVTtmB/92VoJ2gzaws9XdiFdoI2s7bQhfnZCdrMqk/yTUIzs8rqwiFoJ2gzaw++SWhmVkEim8nRbRomaEkXNHo/Ir7d3OaYmeXrwg70gD3o3dLPDwBHkO0gAPCnwN1lNcrM7F0K7pbSaRom6Ij4OwBJtwNTIuLFdP514Kelt87MLOnC/Fx4DPp9wOs1568D45veGjOzHMIPqjRyHfCApFvItgk/Bbi2tFaZmfXjWRx1RMTFkm4DjkmhMyPi4fKaZWb2jiZsCNuWBjPNbhfghYj4iaR9JB0YEU+U1TAzs1oe4qhD0kXAVLLZHD8BhgP/BBxdXtPMzN7Rfem5eA/6FOAwYDlARGyQtFvjj5iZNY+n2dX3ekSEpACQ9EcltsnM7F2yWRytbsXQK5qgb5L0I2CUpC8Afwn8uLxmmZnVkBfsrysi/lHSCcALZOPQ/yMilpTaMjOzGh7iqEPSpRHxFWBJTszMrFTdOsTRU7DcCTmxk5rZEDOzRpTW4xjo6CQNE7SkcyStAj4oaWXN8QSwamiaaGbWt+TowMeA15F2lvSApH+XtFpS35pDB0q6X9IaSTdKGpHiO6Xzten98TXXmpPiv5Z0Yk18RoqtlXRhTTy3jnoG6kFfT7Zy3a3pZ99xeET8RYE/CzOzHSZBb48KHQX8HvhERBwKTAZmSJoGXApcFhETgK3AWan8WcDWiDgYuCyVQ9JE4DTgw8AM4ApJvZJ6gR+QjTJMBE5PZWlQR66GCToino+IJ4HvAlsi4qmIeAp4Q9JRRf4kzMyaoVlDHJF5KZ0OT0cAnwB+luLzgZPT65npnPT+8coqmgksiIjfp6eq1wJHpmNtRKyLiNeBBcDM9Jl6deQqOgZ9JfBSzfnLKWZmNiT61uMY6ABGS1pWc5z9h9dSr6QVwCayyQ+PA7+LiG2pyHpgbHo9FngGIL3/PLB3bbzfZ+rF925QR66i86AVEdF3EhFvSfJ2WWY2JIQGsxbH5oiY2qhARLwJTJY0CrgF+FBesberz3+vXjyv49uofF1Fe9DrJP1XScPTcR6wruBnzcx2TMHe82AncUTE74ClwDSyB/H6Op7jgA3p9Xpgf4D0/h7Altp4v8/Ui29uUEeuor3gvwIuB/6WLOPfAfzBPxva0WEfeh+/vP/7rW6GmQ2gWVPoJO0DvBERv5M0Evgk2c27u4BTycaMZ5NNjoBsq7/ZwL3p/TvT0hcLgeslfRt4LzABeICspzxB0oHAs2Q3Es9In6lXR66iTxJuSpWYmQ05Ab3Nm+M8BpifZlv0ADdFxM8lPQoskPQt4GHg6lT+auA6SWvJes6nAUTEakk3AY8C24Bz09AJkr4ILAZ6gXkRsTpd6yt16shV9EnCQ8huCu4XEZMkfQT4dER8q8jnzcx2VLOeJIyIlWSrc/aPryObgdE//hrwmTrXuhi4OCe+CFhUtI56io5BXwXMAd5IlazEPWozG0I9KnZ0kqJj0LtExAP9xoC21StsZtZM2Q3ADsu+BRRN0JslHUSaEiLpVGBjaa0yM+un03rHRRRN0OcCc8nW5HgWeALwo95mNmS6sANdeBbHOuCTaSeVnoh4sdxmmZm9Q8CwLszQhW4SStpb0uXAPcBSSd+VtHe5TTMze0cZD6pUXdFZHAuA3wB/TjbJ+jfAjWU1ysyslpQ96l3k6CRFx6D3iohv1px/S1LDVZjMzJqpw3JvIUV70HdJOk1STzo+C/yizIaZmdXyPOj6/hNwAXBdOu8FXpZ0AdnyqruX0TgzM0iPenda9i2g6CyO3cpuiJlZXR3YOy6i6CyOs/qd90q6qJwmmZn9IRX8XycpOgZ9vKRFksZI+mPgPsC9ajMbEsJj0HVFxBmS/iPZTt6vAKdHxC9LbZmZWY1OS75FFB3imACcB9wMPAl8TtIuJbbLzOxdmrVpbDspOovjf5MtRn1H2pn2AuBBsu3GzcxKJUFv0QHZDlI0QR8ZES9ANqcO+J9puxczsyHRaU8JFtHw7yRJfwMQES9I6r+jwJmltcrMrEa33iQc6B8NtbumzOn33owmt8XMrK5uXCxpoCEO1Xmdd25mVhLR04UpZ6AEHXVe552bmZVCdF7vuIiBEvShkl4g+/MZmV6TzncutWVmZn0EwzptgLmAhgk6InqHqiFmZvW4B21mVmHdOM3OCdrM2kIX5mcnaDOrPlF8ZbdO4gRtZtUnD3GYmVVS9iRh9yXobvxXg5m1IRU8BryOtL+kuyQ9Jmm1pPNSfC9JSyStST/3THFJulzSWkkrJU2pudbsVH6NpNk18cMlrUqfuTwtMle3jnqcoM2sLTTxUe9twH+LiA8B04BzJU0ELgTuiIgJwB3pHOAkYEI6zgauzNqjvYCLgKOAI4GLahLulals3+f6lsaoV0cuJ2gzawPF1oIush50RGyMiOXp9YvAY8BYYCYwPxWbD5ycXs8Ero3MfcAoSWOAE4ElEbElIrYCS4AZ6b3dI+LetPrntf2ulVdHLo9Bm1nlDXIWx2hJy2rO50bE3NzrSuOBw4D7gf0iYiNkSVzSvqnYWOCZmo+tT7FG8fU5cRrUkcsJ2szawiBuEm6OiKkDFZK0K9kuUV9KSyrXLZoTi+2ID5qHOMys+tTcLa8kDSdLzv8cEf8rhZ9LwxOkn5tSfD2wf83HxwEbBoiPy4k3qiOXE7SZVV7fEEeRY8BrZVn8auCxiPh2zVsLgb6ZGLOBW2vis9JsjmnA82mYYjEwXdKe6ebgdGBxeu9FSdNSXbP6XSuvjlwe4jCzttDEDWGPBj4HrJK0IsW+ClwC3CTpLOBpoG8XqUXAp4C1wCuk3aQiYoukb5LtzwrwjYjYkl6fA1wDjARuSwcN6sjlBG1mbaFZ6Tki/q3B5Y7PKR/AuXWuNQ+YlxNfBkzKif82r456nKDNrPIE9Hbhk4RO0GbWFrowPztBm1k7EPKehGZm1eQetJlZBWXT7LovQztBm1n1FV8IqaM4QZtZW+jG9aCdoM2s8rIF+1vdiqHnBG1mbcGzOMzMKqoLRzicoM2sPXRjD7q01ewkvUfSAkmPS3pU0iJJh0gaL+mRkuo8VtJySdsknVpGHWY29PrGoIscnaSUHnRaYu8WYH5EnJZik4H9ePcOBM32NPB54K9LrMPMhprUlbM4yupBHwe8ERE/7AtExIqIuKe2UOpN35N6vcslfTTFx0i6W9IKSY9IOkZSr6Rr0vkqSef3rzQinoyIlcBbJf1eZtYizdrVu52UNQY9CXioQLlNwAkR8ZqkCcANwFTgDLKFry+W1AvsAkwGxkbEJABJo7a3cZLOJttxl/3f977tvYyZDZFsiKPT0u/AWr2jynDgKkmrgJ8CE1P8QeBMSV8H/jjtvLsOeL+k70maAbywvZVGxNyImBoRU/cZvc+O/QZmNiS6sQddVoJeDRxeoNz5wHPAoWQ95xEAEXE3cCzwLHCdpFlpW/NDgaVki2f/uPnNNrPK6sIMXVaCvhPYSdIX+gKSjpD0sX7l9gA2RsRbZFvQ9KayBwCbIuIqsr3DpkgaDfRExM3A14ApJbXdzCqoJ90oHOjoJKUk6LRFzCnACWma3Wrg67yzs22fK4DZku4DDgFeTvGPAyskPQz8OfBdYCywNO0hdg0wp3+96S+B9WT7fP0o1WtmHaALO9DlPagSERuAz9Z5e1Iqswb4SE18TorPB+bnfK5hrzkiHuTd252bWafotOxbgJ8kNLPKy3rH3ZehnaDNrPq8HrSZWXV1YX52gjazdiDUhV1oJ2gzawtdmJ+doM2s+jpxCl0RTtBm1h66MEM7QZtZW+jGaXatXizJzKwQqdgx8HU0T9Km2o1DJO0laYmkNennnikuSZdLWitppaQpNZ+ZncqvkTS7Jn54WhJ5bfqsGtXRiBO0mVVfweRc8EbiNcCMfrELgTsiYgJwRzoHOAmYkI6zgSshS7bARcBRwJHARTUJ98pUtu9zMwaooy4naDNrCyr4v4Gk1TK39AvP5J3lJeYDJ9fEr43MfcAoSWOAE4ElEbElrbS5BJiR3ts9Iu5NaxJd2+9aeXXU5TFoM6s8Ufo0u/0iYiNARGyUtG+Kj+Xd2/StT7FG8fU58UZ11OUEbWZtYRD5ebSkZTXncyNibhOrje2IbxcnaDNrD8Uz9OaImDrIqz8naUzq2Y4h244Psh7w/jXlxpEtm7yebFnk2vjSFB+XU75RHXV5DNrM2kLJC/YvBPpmYswGbq2Jz0qzOaYBz6dhisXAdEl7ppuD08n2Ud0IvChpWpq9MavftfLqqMs9aDNrC80agpZ0A1nvd3Ta4OMi4BLgJklnAU+TbfoBsAj4FLAWeAU4EyAitkj6Jtn+qQDfiIi+G4/nkM0UGQnclg4a1FGXE7SZtYcmZeiIOL3OW8fnlA2yPVDzrjMPmJcTX0balKRf/Ld5dTTiBG1mlecF+83MqsoL9puZVVcX5mcnaDNrB16w38yssrowPztBm1n1ecF+M7Mq68IM7QRtZm3B0+zMzCrKY9BmZlUk6HGCNjOrqu7L0E7QZlZ5Q7BgfyU5QZtZW+jC/OwEbWbtwT1oM7OK8qPeZmYV1X3p2QnazNqAvNyomVl1+UlCM7Oq6r787ARtZu2hC/OzE7SZtQPR04WD0E7QZlZ53fokYU+rG2BmZvncgzazttCNPWgnaDNrC55mZ2ZWRX5Qxcysmrr1JqETtJm1BQ9xmJlVVDf2oD3Nzszaggoeha4lzZD0a0lrJV1YRnubwQnazNpDkzK0pF7gB8BJwETgdEkTS2nzDnKCNrPKE9AjFToKOBJYGxHrIuJ1YAEws8z2b6+uH4NevvyhzSOH66lWt6MEo4HNrW6EDUonf2cH7MiHly9/aPHI4RpdsPjOkpbVnM+NiLk152OBZ2rO1wNH7Uj7ytL1CToi9ml1G8ogaVlETG11O6w4f2f1RcSMJl4ur5sdTbx+03iIw8y6zXpg/5rzccCGFrWlISdoM+s2DwITJB0oaQRwGrCwxW3K1fVDHB1s7sBFrGL8nQ2BiNgm6YvAYqAXmBcRq1vcrFyKqOTQi7U5SW8Cq8g6AY8BsyPile281seBv46IP5H0aWBiRFxSp+wo4IyIuGKQdXwdeCki/nF72mhWBg9xWFlejYjJETEJeB34q9o3lRn0//8iYmG95JyMAv7zYK9rVkVO0DYU7gEOljRe0mOSrgCWA/tLmi7pXknLJf1U0q7w9pNev5L0b8Cf9V1I0uclfT+93k/SLZL+PR0fBS4BDpK0QtI/pHJflvSgpJWS/q7mWv89PU32f4APDNmfhllBTtBWKknDyJ7YWpVCHwCujYjDgJeBvwU+GRFTgGXABZJ2Bq4C/hQ4BnhPnctfDvzfiDgUmAKsBi4EHk+99y9Lmg5MIHs4YTJwuKRjJR1OdnPoMLK/AI5o8q9utsN8k9DKMlLSivT6HuBq4L3AUxFxX4pPI3vU9pfKngAbAdwLfBB4IiLWAEj6J+DsnDo+AcwCiIg3gecl7dmvzPR0PJzOdyVL2LsBt/SNi0uq5F18625O0FaWVyNicm0gJeGXa0PAkog4vV+5yTTvwQEBfx8RP+pXx5eaWIdZKTzEYa10H3C0pIMBJO0i6RDgV8CBkg5K5U6v8/k7gHPSZ3sl7Q68SNY77rMY+Muase2xkvYF7gZOkTRS0m5kwylmleIEbS0TEb8BPg/cIGklWcL+YES8Rjak8Yt0k7DeWinnAcdJWgU8BHw4In5LNmTyiKR/iIjbgeuBe1O5nwG7RcRy4EZgBXAz2TCMWaV4HrSZWUW5B21mVlFO0GZmFeUEbWZWUU7QZmYV5QRtZlZRTtBmZhXlBG1mVlH/H8iATcDyNlzeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['Class 0', 'Class 1']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(conf_mat , cmap=plt.cm.Blues)\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Expected')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(dims, act='relu', init='glorot_uniform'):\n",
    "\n",
    "    n_stacks = len(dims) - 1\n",
    "    input_img = Input(shape=(dims[0],), name='input')\n",
    "    x = input_img\n",
    "    for i in range(n_stacks-1):\n",
    "        x = Dense(dims[i + 1], activation=act, kernel_initializer=init, name='encoder_%d' % i)(x)\n",
    "\n",
    "    encoded = Dense(dims[-1], kernel_initializer=init, name='encoder_%d' % (n_stacks - 1))(x)  \n",
    "\n",
    "    x = encoded\n",
    "    for i in range(n_stacks-1, 0, -1):\n",
    "        x = Dense(dims[i], activation=act, kernel_initializer=init, name='decoder_%d' % i)(x)\n",
    "\n",
    "    x = Dense(dims[0], kernel_initializer=init, name='decoder_0')(x)\n",
    "    decoded = x\n",
    "    return Model(inputs=input_img, outputs=decoded, name='AE'), Model(inputs=input_img, outputs=encoded, name='encoder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [x_all.shape[-1], 500, 500, 2000, 10]\n",
    "init = VarianceScaling(scale=1. / 3., mode='fan_in',\n",
    "                           distribution='uniform')\n",
    "pretrain_optimizer = SGD(lr=0.1, momentum=0.9)\n",
    "pretrain_epochs = 100\n",
    "batch_size = 256\n",
    "save_dir = r'C:\\Users\\YALAVI\\Anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\vector_ar\\tests\\results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder, encoder = autoencoder(dims, init=init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "usualCallback = EarlyStopping()\n",
    "\n",
    "overfitCallback = EarlyStopping(monitor='loss', min_delta=0, patience = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-train autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "699301/699301 [==============================] - 323s 462us/step - loss: 0.0706\n",
      "Epoch 2/100\n",
      "699301/699301 [==============================] - 317s 454us/step - loss: 0.0256\n",
      "Epoch 3/100\n",
      "699301/699301 [==============================] - 342s 488us/step - loss: 0.0206\n",
      "Epoch 4/100\n",
      "699301/699301 [==============================] - 344s 491us/step - loss: 0.0179\n",
      "Epoch 5/100\n",
      "699301/699301 [==============================] - 330s 471us/step - loss: 0.0161\n",
      "Epoch 6/100\n",
      "699301/699301 [==============================] - 332s 475us/step - loss: 0.0147\n",
      "Epoch 7/100\n",
      "699301/699301 [==============================] - 309s 442us/step - loss: 0.0138\n",
      "Epoch 8/100\n",
      "699301/699301 [==============================] - 312s 446us/step - loss: 0.0130\n",
      "Epoch 9/100\n",
      "699301/699301 [==============================] - 319s 456us/step - loss: 0.0124\n",
      "Epoch 10/100\n",
      "699301/699301 [==============================] - 347s 496us/step - loss: 0.0118\n",
      "Epoch 11/100\n",
      "699301/699301 [==============================] - 363s 519us/step - loss: 0.0113\n",
      "Epoch 12/100\n",
      "699301/699301 [==============================] - 315s 451us/step - loss: 0.0109\n",
      "Epoch 13/100\n",
      "699301/699301 [==============================] - 323s 462us/step - loss: 0.0105\n",
      "Epoch 14/100\n",
      "699301/699301 [==============================] - 328s 468us/step - loss: 0.0101\n",
      "Epoch 15/100\n",
      "699301/699301 [==============================] - 335s 479us/step - loss: 0.0098\n",
      "Epoch 16/100\n",
      "699301/699301 [==============================] - 331s 474us/step - loss: 0.0095\n",
      "Epoch 17/100\n",
      "699301/699301 [==============================] - 327s 467us/step - loss: 0.0093\n",
      "Epoch 18/100\n",
      "699301/699301 [==============================] - 339s 485us/step - loss: 0.0090\n",
      "Epoch 19/100\n",
      "699301/699301 [==============================] - 324s 464us/step - loss: 0.0088\n",
      "Epoch 20/100\n",
      "699301/699301 [==============================] - 320s 458us/step - loss: 0.0086\n",
      "Epoch 21/100\n",
      "  8192/699301 [..............................] - ETA: 5:02 - loss: 0.0085"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-052cfa4f3854>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpretrain_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpretrain_epochs\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moverfitCallback\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;31m#, callbacks=cb)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/ae_weights.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3792\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3794\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m     \"\"\"\n\u001b[1;32m-> 1605\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1645\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "autoencoder.compile(optimizer=pretrain_optimizer, loss='mse')\n",
    "autoencoder.fit(x_all, x_all, batch_size=batch_size, epochs=pretrain_epochs , callbacks=[overfitCallback] ) #, callbacks=cb)\n",
    "autoencoder.save_weights(save_dir + '/ae_weights.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "autoencoder.save_weights(save_dir + '/ae_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Load the pre-trained auto encoder weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights(save_dir + '/ae_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build clustering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClusteringLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusteringLayer(Layer):\n",
    "\n",
    "\n",
    "    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(ClusteringLayer, self).__init__(**kwargs)\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = InputSpec(ndim=2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
    "        self.clusters = self.add_weight(shape=(self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "\n",
    "        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
    "        q **= (self.alpha + 1.0) / 2.0\n",
    "        q = K.transpose(K.transpose(q) / K.sum(q, axis=1)) \n",
    "        return q\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return input_shape[0], self.n_clusters\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'n_clusters': self.n_clusters}\n",
    "        base_config = super(ClusteringLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 2\n",
    "clustering_layer = ClusteringLayer(n_clusters , name='clustering')(encoder.output)\n",
    "model = Model(inputs=encoder.input, outputs=clustering_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(0.01, 0.9), loss='kld')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: initialize cluster centers using k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=n_clusters, n_init=20)\n",
    "y_pred = kmeans.fit_predict(encoder.predict(x_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_last = np.copy(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: deep clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_distribution(q):\n",
    "    weight = q ** 2 / q.sum(0)\n",
    "    return (weight.T / weight.sum(1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0\n",
    "index = 0\n",
    "maxiter = 8000\n",
    "update_interval = 140\n",
    "index_array = np.arange(x_all.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 0.001 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: acc = 0.73294, nmi = 0.00009, ari = -0.00051  ; loss= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 140: acc = 0.72353, nmi = 0.00006, ari = -0.00041  ; loss= 0.00449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 280: acc = 0.70591, nmi = 0.00008, ari = -0.00042  ; loss= 0.00889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 420: acc = 0.60053, nmi = 0.00018, ari = -0.00031  ; loss= 0.00879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 560: acc = 0.56907, nmi = 0.00021, ari = -0.00023  ; loss= 0.01453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 700: acc = 0.56641, nmi = 0.00020, ari = -0.00022  ; loss= 0.0118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 840: acc = 0.56613, nmi = 0.00020, ari = -0.00021  ; loss= 0.00962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 980: acc = 0.56362, nmi = 0.00019, ari = -0.00020  ; loss= 0.00939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1120: acc = 0.56387, nmi = 0.00020, ari = -0.00021  ; loss= 0.00933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1260: acc = 0.56352, nmi = 0.00019, ari = -0.00021  ; loss= 0.01409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1400: acc = 0.56177, nmi = 0.00020, ari = -0.00020  ; loss= 0.01519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1540: acc = 0.56021, nmi = 0.00020, ari = -0.00020  ; loss= 0.01914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1680: acc = 0.56029, nmi = 0.00020, ari = -0.00020  ; loss= 0.00888\n",
      "delta_label  0.0005576997601891031 < tol  0.001\n",
      "Reached tolerance threshold. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "for ite in range(int(maxiter)):\n",
    "    if ite % update_interval == 0:\n",
    "        q = model.predict(x_all, verbose=0)\n",
    "        p = target_distribution(q) \n",
    "\n",
    "        y_pred = q.argmax(1)\n",
    "        if Y_all is not None:\n",
    "            acc = np.round(metrics.acc(Y_all, y_pred), 5)\n",
    "            nmi = np.round(metrics.nmi(Y_all, y_pred), 5)\n",
    "            ari = np.round(metrics.ari(Y_all, y_pred), 5)\n",
    "            loss = np.round(loss, 5)\n",
    "            print('Iter %d: acc = %.5f, nmi = %.5f, ari = %.5f' % (ite, acc, nmi, ari), ' ; loss=', loss)\n",
    "\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        if ite > 0 and delta_label < tol:\n",
    "            print('delta_label ', delta_label, '< tol ', tol)\n",
    "            print('Reached tolerance threshold. Stopping training.')\n",
    "            break\n",
    "    idx = index_array[index * batch_size: min((index+1) * batch_size, x_all.shape[0])]\n",
    "    loss = model.train_on_batch(x=x_all[idx], y=p[idx])\n",
    "    index = index + 1 if (index + 1) * batch_size <= x_all.shape[0] else 0\n",
    "\n",
    "model.save_weights(save_dir + '/DEC_model_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the clustering model trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(save_dir + '/DEC_model_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YALAVI\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc = 0.56029, nmi = 0.00020, ari = -0.00020  ; loss= 0.00888\n"
     ]
    }
   ],
   "source": [
    "q = model.predict(x_all, verbose=0)\n",
    "p = target_distribution(q)\n",
    "\n",
    "y_pred = q.argmax(1)\n",
    "if Y_all is not None:\n",
    "    acc = np.round(metrics.acc(Y_all, y_pred), 5)\n",
    "    nmi = np.round(metrics.nmi(Y_all, y_pred), 5)\n",
    "    ari = np.round(metrics.ari(Y_all, y_pred), 5)\n",
    "    loss = np.round(loss, 5)\n",
    "    print('Acc = %.5f, nmi = %.5f, ari = %.5f' % (acc, nmi, ari), ' ; loss=', loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
